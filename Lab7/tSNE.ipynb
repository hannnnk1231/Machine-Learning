{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  tsne.py\n",
    "#\n",
    "# Implementation of t-SNE in Python. The implementation was tested on Python\n",
    "# 2.7.10, and it requires a working installation of NumPy. The implementation\n",
    "# comes with an example on the MNIST dataset. In order to plot the\n",
    "# results of this example, a working installation of matplotlib is required.\n",
    "#\n",
    "# The example can be run by executing: `ipython tsne.py`\n",
    "#\n",
    "#\n",
    "#  Created by Laurens van der Maaten on 20-12-08.\n",
    "#  Copyright (c) 2008 Tilburg University. All rights reserved.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hbeta(D=np.array([]), beta=1.0):\n",
    "    \"\"\"\n",
    "        Compute the perplexity and the P-row for a specific value of the\n",
    "        precision of a Gaussian distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute P-row and corresponding perplexity\n",
    "    P = np.exp(-D.copy() * beta)\n",
    "    sumP = sum(P)\n",
    "    H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "    P = P / sumP\n",
    "    return H, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x2p(X=np.array([]), tol=1e-5, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Performs a binary search to get P-values in such a way that each\n",
    "        conditional Gaussian has the same perplexity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize some variables\n",
    "    print(\"Computing pairwise distances...\")\n",
    "    (n, d) = X.shape\n",
    "    sum_X = np.sum(np.square(X), 1)\n",
    "    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "    P = np.zeros((n, n))\n",
    "    beta = np.ones((n, 1))\n",
    "    logU = np.log(perplexity)\n",
    "\n",
    "    # Loop over all datapoints\n",
    "    for i in range(n):\n",
    "\n",
    "        # Print progress\n",
    "        if i % 500 == 0:\n",
    "            print(\"Computing P-values for point %d of %d...\" % (i, n))\n",
    "\n",
    "        # Compute the Gaussian kernel and entropy for the current precision\n",
    "        betamin = -np.inf\n",
    "        betamax = np.inf\n",
    "        Di = D[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))]\n",
    "        (H, thisP) = Hbeta(Di, beta[i])\n",
    "\n",
    "        # Evaluate whether the perplexity is within tolerance\n",
    "        Hdiff = H - logU\n",
    "        tries = 0\n",
    "        while np.abs(Hdiff) > tol and tries < 50:\n",
    "\n",
    "            # If not, increase or decrease precision\n",
    "            if Hdiff > 0:\n",
    "                betamin = beta[i].copy()\n",
    "                if betamax == np.inf or betamax == -np.inf:\n",
    "                    beta[i] = beta[i] * 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamax) / 2.\n",
    "            else:\n",
    "                betamax = beta[i].copy()\n",
    "                if betamin == np.inf or betamin == -np.inf:\n",
    "                    beta[i] = beta[i] / 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamin) / 2.\n",
    "\n",
    "            # Recompute the values\n",
    "            (H, thisP) = Hbeta(Di, beta[i])\n",
    "            Hdiff = H - logU\n",
    "            tries += 1\n",
    "\n",
    "        # Set the final row of P\n",
    "        P[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))] = thisP\n",
    "\n",
    "    # Return final P-matrix\n",
    "    print(\"Mean value of sigma: %f\" % np.mean(np.sqrt(1 / beta)))\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X=np.array([]), no_dims=50):\n",
    "    \"\"\"\n",
    "        Runs PCA on the NxD array X in order to reduce its dimensionality to\n",
    "        no_dims dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Preprocessing the data using PCA...\")\n",
    "    (n, d) = X.shape\n",
    "    X = X - np.tile(np.mean(X, 0), (n, 1))\n",
    "    (l, M) = np.linalg.eig(np.dot(X.T, X))\n",
    "    Y = np.dot(X, M[:, 0:no_dims])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne(X=np.array([]), no_dims=2, initial_dims=50, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Runs t-SNE on the dataset in the NxD array X to reduce its\n",
    "        dimensionality to no_dims dimensions. The syntaxis of the function is\n",
    "        `Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check inputs\n",
    "    if isinstance(no_dims, float):\n",
    "        print(\"Error: array X should have type float.\")\n",
    "        return -1\n",
    "    if round(no_dims) != no_dims:\n",
    "        print(\"Error: number of dimensions should be an integer.\")\n",
    "        return -1\n",
    "\n",
    "    # Initialize variables\n",
    "    X = pca(X, initial_dims).real\n",
    "    (n, d) = X.shape\n",
    "    max_iter = 1000\n",
    "    initial_momentum = 0.5\n",
    "    final_momentum = 0.8\n",
    "    eta = 500\n",
    "    min_gain = 0.01\n",
    "    Y = np.random.randn(n, no_dims)\n",
    "    dY = np.zeros((n, no_dims))\n",
    "    iY = np.zeros((n, no_dims))\n",
    "    gains = np.ones((n, no_dims))\n",
    "\n",
    "    # Compute P-values\n",
    "    P = x2p(X, 1e-5, perplexity)\n",
    "    P = P + np.transpose(P)\n",
    "    P = P / np.sum(P)\n",
    "    P = P * 4.\t\t\t\t\t\t\t\t\t# early exaggeration\n",
    "    P = np.maximum(P, 1e-12)\n",
    "\n",
    "    # Run iterations\n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        # Compute pairwise affinities\n",
    "        sum_Y = np.sum(np.square(Y), 1)\n",
    "        num = -2. * np.dot(Y, Y.T)\n",
    "        num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "        num[range(n), range(n)] = 0.\n",
    "        Q = num / np.sum(num)\n",
    "        Q = np.maximum(Q, 1e-12)\n",
    "\n",
    "        # Compute gradient\n",
    "        PQ = P - Q\n",
    "        for i in range(n):\n",
    "            dY[i, :] = np.sum(np.tile(PQ[:, i] * num[:, i], (no_dims, 1)).T * (Y[i, :] - Y), 0)\n",
    "\n",
    "        # Perform the update\n",
    "        if iter < 20:\n",
    "            momentum = initial_momentum\n",
    "        else:\n",
    "            momentum = final_momentum\n",
    "        gains = (gains + 0.2) * ((dY > 0.) != (iY > 0.)) + \\\n",
    "                (gains * 0.8) * ((dY > 0.) == (iY > 0.))\n",
    "        gains[gains < min_gain] = min_gain\n",
    "        iY = momentum * iY - eta * (gains * dY)\n",
    "        Y = Y + iY\n",
    "        Y = Y - np.tile(np.mean(Y, 0), (n, 1))\n",
    "\n",
    "        # Compute current value of cost function\n",
    "        if (iter + 1) % 10 == 0:\n",
    "            C = np.sum(P * np.log(P / Q))\n",
    "            print(\"Iteration %d: error is %f\" % (iter + 1, C))\n",
    "\n",
    "        # Stop lying about P-values\n",
    "        if iter == 100:\n",
    "            P = P / 4.\n",
    "        plt.scatter(Y[:, 0], Y[:, 1], 20, labels)\n",
    "        plt.title('t-SNE, Iter{}'.format(iter+1))\n",
    "        plt.savefig('tsne/tsne-iter{}.png'.format(iter+1))\n",
    "\n",
    "    # Return solution\n",
    "    return Y,P,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssne(X=np.array([]), no_dims=2, initial_dims=50, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Runs t-SNE on the dataset in the NxD array X to reduce its\n",
    "        dimensionality to no_dims dimensions. The syntaxis of the function is\n",
    "        `Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check inputs\n",
    "    if isinstance(no_dims, float):\n",
    "        print(\"Error: array X should have type float.\")\n",
    "        return -1\n",
    "    if round(no_dims) != no_dims:\n",
    "        print(\"Error: number of dimensions should be an integer.\")\n",
    "        return -1\n",
    "\n",
    "    # Initialize variables\n",
    "    X = pca(X, initial_dims).real\n",
    "    (n, d) = X.shape\n",
    "    max_iter = 1000\n",
    "    initial_momentum = 0.5\n",
    "    final_momentum = 0.8\n",
    "    eta = 500\n",
    "    min_gain = 0.01\n",
    "    Y = np.random.randn(n, no_dims)\n",
    "    dY = np.zeros((n, no_dims))\n",
    "    iY = np.zeros((n, no_dims))\n",
    "    gains = np.ones((n, no_dims))\n",
    "\n",
    "    # Compute P-values\n",
    "    P = x2p(X, 1e-5, perplexity)\n",
    "    P = P + np.transpose(P)\n",
    "    P = P / np.sum(P)\n",
    "    P = P * 4.\t\t\t\t\t\t\t\t\t# early exaggeration\n",
    "    P = np.maximum(P, 1e-12)\n",
    "\n",
    "    # Run iterations\n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        # Compute pairwise affinities\n",
    "        sum_Y = np.sum(np.square(Y), 1)\n",
    "        num = -2. * np.dot(Y, Y.T)\n",
    "        #num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "        num = np.exp(-1*np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "        num[range(n), range(n)] = 0.\n",
    "        Q = num / np.sum(num)\n",
    "        Q = np.maximum(Q, 1e-12)\n",
    "\n",
    "        # Compute gradient\n",
    "        PQ = P - Q\n",
    "        for i in range(n):\n",
    "            #dY[i, :] = np.sum(np.tile(PQ[:, i] * num[:, i], (no_dims, 1)).T * (Y[i, :] - Y), 0)\n",
    "            dY[i, :] = np.sum(np.tile(PQ[:, i], (no_dims, 1)).T * (Y[i, :] - Y), 0)\n",
    "\n",
    "        # Perform the update\n",
    "        if iter < 20:\n",
    "            momentum = initial_momentum\n",
    "        else:\n",
    "            momentum = final_momentum\n",
    "        gains = (gains + 0.2) * ((dY > 0.) != (iY > 0.)) + \\\n",
    "                (gains * 0.8) * ((dY > 0.) == (iY > 0.))\n",
    "        gains[gains < min_gain] = min_gain\n",
    "        iY = momentum * iY - eta * (gains * dY)\n",
    "        Y = Y + iY\n",
    "        Y = Y - np.tile(np.mean(Y, 0), (n, 1))\n",
    "\n",
    "        # Compute current value of cost function\n",
    "        if (iter + 1) % 10 == 0:\n",
    "            C = np.sum(P * np.log(P / Q))\n",
    "            print(\"Iteration %d: error is %f\" % (iter + 1, C))\n",
    "\n",
    "        # Stop lying about P-values\n",
    "        if iter == 100:\n",
    "            P = P / 4.\n",
    "        plt.scatter(Y[:, 0], Y[:, 1], 20, labels)\n",
    "        plt.title('S-SNE, Iter{}'.format(iter+1))\n",
    "        plt.savefig('ssne/ssne-iter{}.png'.format(iter+1))\n",
    "    # Return solution\n",
    "    return Y,P,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Y = tsne.tsne(X, no_dims, perplexity) to perform t-SNE on your dataset.\n",
      "Running example on 2,500 MNIST digits...\n",
      "Preprocessing the data using PCA...\n",
      "Computing pairwise distances...\n",
      "Computing P-values for point 0 of 2500...\n",
      "Computing P-values for point 500 of 2500...\n",
      "Computing P-values for point 1000 of 2500...\n",
      "Computing P-values for point 1500 of 2500...\n",
      "Computing P-values for point 2000 of 2500...\n",
      "Mean value of sigma: 2.386597\n",
      "Iteration 10: error is 23.643289\n",
      "Iteration 20: error is 21.296890\n",
      "Iteration 30: error is 18.115631\n",
      "Iteration 40: error is 16.745834\n",
      "Iteration 50: error is 16.358275\n",
      "Iteration 60: error is 16.219201\n",
      "Iteration 70: error is 16.118672\n",
      "Iteration 80: error is 16.037023\n",
      "Iteration 90: error is 15.984782\n",
      "Iteration 100: error is 15.941957\n",
      "Iteration 110: error is 2.323597\n",
      "Iteration 120: error is 2.079536\n",
      "Iteration 130: error is 1.893859\n",
      "Iteration 140: error is 1.755204\n",
      "Iteration 150: error is 1.649271\n",
      "Iteration 160: error is 1.565774\n",
      "Iteration 170: error is 1.498885\n",
      "Iteration 180: error is 1.444287\n",
      "Iteration 190: error is 1.398874\n",
      "Iteration 200: error is 1.360672\n",
      "Iteration 210: error is 1.327915\n",
      "Iteration 220: error is 1.300064\n",
      "Iteration 230: error is 1.276304\n",
      "Iteration 240: error is 1.255683\n",
      "Iteration 250: error is 1.237556\n",
      "Iteration 260: error is 1.221418\n",
      "Iteration 270: error is 1.206851\n",
      "Iteration 280: error is 1.193633\n",
      "Iteration 290: error is 1.181764\n",
      "Iteration 300: error is 1.171073\n",
      "Iteration 310: error is 1.161419\n",
      "Iteration 320: error is 1.152612\n",
      "Iteration 330: error is 1.144525\n",
      "Iteration 340: error is 1.137077\n",
      "Iteration 350: error is 1.130215\n",
      "Iteration 360: error is 1.123887\n",
      "Iteration 370: error is 1.118001\n",
      "Iteration 380: error is 1.112504\n",
      "Iteration 390: error is 1.107360\n",
      "Iteration 400: error is 1.102530\n",
      "Iteration 410: error is 1.098062\n",
      "Iteration 420: error is 1.093854\n",
      "Iteration 430: error is 1.089935\n",
      "Iteration 440: error is 1.086244\n",
      "Iteration 450: error is 1.082757\n",
      "Iteration 460: error is 1.079473\n",
      "Iteration 470: error is 1.076363\n",
      "Iteration 480: error is 1.073409\n",
      "Iteration 490: error is 1.070606\n",
      "Iteration 500: error is 1.067951\n",
      "Iteration 510: error is 1.065422\n",
      "Iteration 520: error is 1.062996\n",
      "Iteration 530: error is 1.060683\n",
      "Iteration 540: error is 1.058464\n",
      "Iteration 550: error is 1.056367\n",
      "Iteration 560: error is 1.054378\n",
      "Iteration 570: error is 1.052474\n",
      "Iteration 580: error is 1.050652\n",
      "Iteration 590: error is 1.048906\n",
      "Iteration 600: error is 1.047234\n",
      "Iteration 610: error is 1.045627\n",
      "Iteration 620: error is 1.044058\n",
      "Iteration 630: error is 1.042547\n",
      "Iteration 640: error is 1.041117\n",
      "Iteration 650: error is 1.039759\n",
      "Iteration 660: error is 1.038454\n",
      "Iteration 670: error is 1.037198\n",
      "Iteration 680: error is 1.035976\n",
      "Iteration 690: error is 1.034810\n",
      "Iteration 700: error is 1.033691\n",
      "Iteration 710: error is 1.032617\n",
      "Iteration 720: error is 1.031585\n",
      "Iteration 730: error is 1.030586\n",
      "Iteration 740: error is 1.029617\n",
      "Iteration 750: error is 1.028679\n",
      "Iteration 760: error is 1.027772\n",
      "Iteration 770: error is 1.026894\n",
      "Iteration 780: error is 1.026043\n",
      "Iteration 790: error is 1.025219\n",
      "Iteration 800: error is 1.024422\n",
      "Iteration 810: error is 1.023651\n",
      "Iteration 820: error is 1.022903\n",
      "Iteration 830: error is 1.022179\n",
      "Iteration 840: error is 1.021478\n",
      "Iteration 850: error is 1.020798\n",
      "Iteration 860: error is 1.020133\n",
      "Iteration 870: error is 1.019473\n",
      "Iteration 880: error is 1.018825\n",
      "Iteration 890: error is 1.018219\n",
      "Iteration 900: error is 1.017632\n",
      "Iteration 910: error is 1.017061\n",
      "Iteration 920: error is 1.016504\n",
      "Iteration 930: error is 1.015962\n",
      "Iteration 940: error is 1.015431\n",
      "Iteration 950: error is 1.014915\n",
      "Iteration 960: error is 1.014411\n",
      "Iteration 970: error is 1.013921\n",
      "Iteration 980: error is 1.013440\n",
      "Iteration 990: error is 1.012967\n",
      "Iteration 1000: error is 1.012504\n",
      "Preprocessing the data using PCA...\n",
      "Computing pairwise distances...\n",
      "Computing P-values for point 0 of 2500...\n",
      "Computing P-values for point 500 of 2500...\n",
      "Computing P-values for point 1000 of 2500...\n",
      "Computing P-values for point 1500 of 2500...\n",
      "Computing P-values for point 2000 of 2500...\n",
      "Mean value of sigma: 2.386597\n",
      "Iteration 10: error is 23.505186\n",
      "Iteration 20: error is 18.773803\n",
      "Iteration 30: error is 17.131031\n",
      "Iteration 40: error is 17.160957\n",
      "Iteration 50: error is 17.061273\n",
      "Iteration 60: error is 16.967348\n",
      "Iteration 70: error is 16.967831\n",
      "Iteration 80: error is 16.949140\n",
      "Iteration 90: error is 16.949150\n",
      "Iteration 100: error is 16.962016\n",
      "Iteration 110: error is 2.276253\n",
      "Iteration 120: error is 2.109066\n",
      "Iteration 130: error is 2.110627\n",
      "Iteration 140: error is 2.128116\n",
      "Iteration 150: error is 2.137211\n",
      "Iteration 160: error is 2.135997\n",
      "Iteration 170: error is 2.134260\n",
      "Iteration 180: error is 2.134102\n",
      "Iteration 190: error is 2.134813\n",
      "Iteration 200: error is 2.135304\n",
      "Iteration 210: error is 2.135532\n",
      "Iteration 220: error is 2.135589\n",
      "Iteration 230: error is 2.135589\n",
      "Iteration 240: error is 2.135589\n",
      "Iteration 250: error is 2.135594\n",
      "Iteration 260: error is 2.135592\n",
      "Iteration 270: error is 2.135590\n",
      "Iteration 280: error is 2.135589\n",
      "Iteration 290: error is 2.135589\n",
      "Iteration 300: error is 2.135588\n",
      "Iteration 310: error is 2.135588\n",
      "Iteration 320: error is 2.135587\n",
      "Iteration 330: error is 2.135587\n",
      "Iteration 340: error is 2.135587\n",
      "Iteration 350: error is 2.135587\n",
      "Iteration 360: error is 2.135587\n",
      "Iteration 370: error is 2.135587\n",
      "Iteration 380: error is 2.135587\n",
      "Iteration 390: error is 2.135587\n",
      "Iteration 400: error is 2.135587\n",
      "Iteration 410: error is 2.135587\n",
      "Iteration 420: error is 2.135587\n",
      "Iteration 430: error is 2.135587\n",
      "Iteration 440: error is 2.135587\n",
      "Iteration 450: error is 2.135587\n",
      "Iteration 460: error is 2.135587\n",
      "Iteration 470: error is 2.135587\n",
      "Iteration 480: error is 2.135587\n",
      "Iteration 490: error is 2.135587\n",
      "Iteration 500: error is 2.135587\n",
      "Iteration 510: error is 2.135587\n",
      "Iteration 520: error is 2.135587\n",
      "Iteration 530: error is 2.135587\n",
      "Iteration 540: error is 2.135587\n",
      "Iteration 550: error is 2.135587\n",
      "Iteration 560: error is 2.135587\n",
      "Iteration 570: error is 2.135587\n",
      "Iteration 580: error is 2.135587\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Run Y = tsne.tsne(X, no_dims, perplexity) to perform t-SNE on your dataset.\")\n",
    "    print(\"Running example on 2,500 MNIST digits...\")\n",
    "    X = np.loadtxt(\"mnist2500_X.txt\")\n",
    "    labels = np.loadtxt(\"mnist2500_labels.txt\")\n",
    "    Y1,P1,Q1 = tsne(X,2,50,20.0)\n",
    "    Y2,P2,Q2 = ssne(X, 2, 50, 20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
